{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e94864b-18a7-421a-998a-eb676110a0cb",
   "metadata": {},
   "source": [
    "## 1. 당뇨병 데이터를 가지고 머신러닝 5가지 분류를 수행하자. \n",
    "(SVM, LR, RF, DT, KNN)\n",
    "#### 1) SVM : Support Vector Machine\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8125b21b-371a-4717-a207-fea8dcb51ef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[81 18]\n",
      " [19 36]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81        99\n",
      "           1       0.67      0.65      0.66        55\n",
      "\n",
      "    accuracy                           0.76       154\n",
      "   macro avg       0.74      0.74      0.74       154\n",
      "weighted avg       0.76      0.76      0.76       154\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 데이터셋 로드 (예: Pima Indians Diabetes Database 등이 있음)\n",
    "# 데이터셋의 경로\n",
    "data = pd.read_csv('diabetes.csv')\n",
    "\n",
    "# 특성과 타겟 변수 분리\n",
    "X = data.drop('Outcome', axis=1)  # 특성\n",
    "y = data['Outcome']               # 타겟 변수\n",
    "\n",
    "# 데이터 분할 (훈련 세트, 테스트 세트)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 데이터 정규화\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# SVM 모델 생성 및 학습\n",
    "model = SVC(kernel='linear')  # 'linear', 'rbf', 'poly' 등 다양한 커널 사용 가능\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 예측\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# 평가\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0098a281-cb93-4d81-8cec-cc683659c578",
   "metadata": {},
   "source": [
    "#### 2) LR : Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9eba336d-a08c-46e7-a92d-d79b363d8169",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[79 20]\n",
      " [18 37]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.81        99\n",
      "           1       0.65      0.67      0.66        55\n",
      "\n",
      "    accuracy                           0.75       154\n",
      "   macro avg       0.73      0.74      0.73       154\n",
      "weighted avg       0.76      0.75      0.75       154\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 데이터셋의 경로를 지정\n",
    "data = pd.read_csv('diabetes.csv')\n",
    "\n",
    "# 특성과 타겟 변수 분리\n",
    "X = data.drop('Outcome', axis=1)  # 특성\n",
    "y = data['Outcome']               # 타겟 변수\n",
    "\n",
    "# 데이터 분할 (훈련 세트, 테스트 세트)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 데이터 정규화\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# 로지스틱 회귀 모델 생성 및 학습\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 예측\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# 평가\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8162891b-ba80-432c-967b-fccf035d1451",
   "metadata": {},
   "source": [
    "#### 3) DT : Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19e677d9-131d-455e-add2-43314be31a18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[75 24]\n",
      " [15 40]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.76      0.79        99\n",
      "           1       0.62      0.73      0.67        55\n",
      "\n",
      "    accuracy                           0.75       154\n",
      "   macro avg       0.73      0.74      0.73       154\n",
      "weighted avg       0.76      0.75      0.75       154\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 데이터셋의 경로를 지정\n",
    "data = pd.read_csv('diabetes.csv')\n",
    "\n",
    "# 특성과 타겟 변수 분리\n",
    "X = data.drop('Outcome', axis=1)  # 특성\n",
    "y = data['Outcome']               # 타겟 변수\n",
    "\n",
    "# 데이터 분할 (훈련 세트, 테스트 세트)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 데이터 정규화 (선택 사항, 결정 트리에 필수는 아님)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# 결정 트리 모델 생성 및 학습\n",
    "model = DecisionTreeClassifier(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 예측\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# 평가\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d55961-8082-4759-81c7-1e99c8c1ff31",
   "metadata": {},
   "source": [
    "#### 4) KNN : K-최근접 이웃 알고리즘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5eb31aef-67b8-4ecd-a48e-8f0f8d3b7735",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[79 20]\n",
      " [27 28]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.80      0.77        99\n",
      "           1       0.58      0.51      0.54        55\n",
      "\n",
      "    accuracy                           0.69       154\n",
      "   macro avg       0.66      0.65      0.66       154\n",
      "weighted avg       0.69      0.69      0.69       154\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 데이터셋의 경로를 지정\n",
    "data = pd.read_csv('diabetes.csv')\n",
    "\n",
    "# 특성과 타겟 변수 분리\n",
    "X = data.drop('Outcome', axis=1)  # 특성\n",
    "y = data['Outcome']                # 타겟 변수\n",
    "\n",
    "# 데이터 분할 (훈련 세트, 테스트 세트)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 데이터 정규화\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# KNN 모델 생성 및 학습\n",
    "model = KNeighborsClassifier(n_neighbors=5)  # k 값 설정\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 예측\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# 평가\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344cedcc-8b02-42ea-958a-3d63f1679853",
   "metadata": {},
   "source": [
    "#### 1번 문제 정리\n",
    "\n",
    "1. 데이터 로드: CSV 파일에서 당뇨병 데이터셋을 로드 <br>\n",
    "2. 데이터 분리: 특성과 타겟 변수를 분리 <br>\n",
    "3. 데이터 분할: 전체 데이터를 훈련 세트와 테스트 세트로 나누기 <br>\n",
    "4. 정규화: KNN 모델은 거리 기반 알고리즘이므로, 정규화를 통해 성능을 향상 시킴 <br>\n",
    "5. 모델 학습: KNN 모델을 생성하고 훈련 데이터로 학습, 여기서 n_neighbors는 K 값으로, 이 값을 조정하여 모델 성능을 최적화할 수 있음 <br>\n",
    "6. 예측 및 평가: 테스트 세트에 대해 예측하고 혼동 행렬 및 분류 보고서를 출력하여 모델 성능을 평가 <br>\n",
    "\n",
    "<br> 모든 과정은 거의 동일한 과정이라 볼 수 있지만 결정 트리의 경우 정규화가 필수는 아님. 또한 모델 학습 부분에서 KNN모델이 조금 특이한 부분이 있지만 결국 비슷한 절차로 성능을 높이려고 하는 거임."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90be1bdd-1124-4547-99c1-19f63382d82a",
   "metadata": {},
   "source": [
    "## 2. 동일한 데이터로 딥러닝 분류 수행하기 (dense layer만 사용)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "076decfb-97f9-4563-8646-e33dd65a6801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 0.6581 - accuracy: 0.6782 - val_loss: 0.6576 - val_accuracy: 0.6829\n",
      "Epoch 2/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.6160 - accuracy: 0.7373 - val_loss: 0.6229 - val_accuracy: 0.6992\n",
      "Epoch 3/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5731 - accuracy: 0.7515 - val_loss: 0.5872 - val_accuracy: 0.7154\n",
      "Epoch 4/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5348 - accuracy: 0.7678 - val_loss: 0.5558 - val_accuracy: 0.7236\n",
      "Epoch 5/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7617 - val_loss: 0.5345 - val_accuracy: 0.7398\n",
      "Epoch 6/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.4827 - accuracy: 0.7658 - val_loss: 0.5156 - val_accuracy: 0.7480\n",
      "Epoch 7/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.4678 - accuracy: 0.7699 - val_loss: 0.5066 - val_accuracy: 0.7317\n",
      "Epoch 8/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.4593 - accuracy: 0.7739 - val_loss: 0.4942 - val_accuracy: 0.7398\n",
      "Epoch 9/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.4502 - accuracy: 0.7862 - val_loss: 0.4896 - val_accuracy: 0.7642\n",
      "Epoch 10/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.4435 - accuracy: 0.7821 - val_loss: 0.4864 - val_accuracy: 0.7642\n",
      "Epoch 11/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.4395 - accuracy: 0.7780 - val_loss: 0.4847 - val_accuracy: 0.7642\n",
      "Epoch 12/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.4356 - accuracy: 0.7882 - val_loss: 0.4855 - val_accuracy: 0.7480\n",
      "Epoch 13/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.4316 - accuracy: 0.7882 - val_loss: 0.4865 - val_accuracy: 0.7480\n",
      "Epoch 14/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.4293 - accuracy: 0.7862 - val_loss: 0.4860 - val_accuracy: 0.7561\n",
      "Epoch 15/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.4269 - accuracy: 0.7862 - val_loss: 0.4843 - val_accuracy: 0.7561\n",
      "Epoch 16/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.4243 - accuracy: 0.7882 - val_loss: 0.4850 - val_accuracy: 0.7642\n",
      "Epoch 17/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.4224 - accuracy: 0.7923 - val_loss: 0.4858 - val_accuracy: 0.7480\n",
      "Epoch 18/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.4210 - accuracy: 0.7923 - val_loss: 0.4864 - val_accuracy: 0.7480\n",
      "Epoch 19/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.4193 - accuracy: 0.7943 - val_loss: 0.4870 - val_accuracy: 0.7561\n",
      "Epoch 20/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.4182 - accuracy: 0.7963 - val_loss: 0.4871 - val_accuracy: 0.7561\n",
      "Epoch 21/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.4150 - accuracy: 0.8004 - val_loss: 0.4858 - val_accuracy: 0.7561\n",
      "Epoch 22/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.4142 - accuracy: 0.8024 - val_loss: 0.4910 - val_accuracy: 0.7642\n",
      "Epoch 23/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.4140 - accuracy: 0.8024 - val_loss: 0.4872 - val_accuracy: 0.7561\n",
      "Epoch 24/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.4129 - accuracy: 0.7984 - val_loss: 0.4897 - val_accuracy: 0.7480\n",
      "Epoch 25/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.4096 - accuracy: 0.7984 - val_loss: 0.4905 - val_accuracy: 0.7561\n",
      "Epoch 26/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.4093 - accuracy: 0.8024 - val_loss: 0.4925 - val_accuracy: 0.7561\n",
      "Epoch 27/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.4075 - accuracy: 0.8086 - val_loss: 0.4909 - val_accuracy: 0.7398\n",
      "Epoch 28/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.4063 - accuracy: 0.8024 - val_loss: 0.4926 - val_accuracy: 0.7561\n",
      "Epoch 29/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.4046 - accuracy: 0.8024 - val_loss: 0.4928 - val_accuracy: 0.7398\n",
      "Epoch 30/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.4030 - accuracy: 0.7963 - val_loss: 0.4934 - val_accuracy: 0.7480\n",
      "Epoch 31/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.4030 - accuracy: 0.8086 - val_loss: 0.4931 - val_accuracy: 0.7480\n",
      "Epoch 32/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.4008 - accuracy: 0.8086 - val_loss: 0.4929 - val_accuracy: 0.7480\n",
      "Epoch 33/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.4018 - accuracy: 0.8065 - val_loss: 0.4845 - val_accuracy: 0.7398\n",
      "Epoch 34/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.3989 - accuracy: 0.8065 - val_loss: 0.4885 - val_accuracy: 0.7398\n",
      "Epoch 35/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.3976 - accuracy: 0.8086 - val_loss: 0.4898 - val_accuracy: 0.7236\n",
      "Epoch 36/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.3964 - accuracy: 0.8086 - val_loss: 0.4919 - val_accuracy: 0.7317\n",
      "Epoch 37/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.3957 - accuracy: 0.8147 - val_loss: 0.4922 - val_accuracy: 0.7317\n",
      "Epoch 38/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.3947 - accuracy: 0.8147 - val_loss: 0.4940 - val_accuracy: 0.7398\n",
      "Epoch 39/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.3932 - accuracy: 0.8187 - val_loss: 0.4885 - val_accuracy: 0.7317\n",
      "Epoch 40/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.3929 - accuracy: 0.8167 - val_loss: 0.4931 - val_accuracy: 0.7398\n",
      "Epoch 41/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.3910 - accuracy: 0.8187 - val_loss: 0.4938 - val_accuracy: 0.7398\n",
      "Epoch 42/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.3896 - accuracy: 0.8147 - val_loss: 0.4947 - val_accuracy: 0.7398\n",
      "Epoch 43/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.3887 - accuracy: 0.8208 - val_loss: 0.4955 - val_accuracy: 0.7398\n",
      "Epoch 44/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.3902 - accuracy: 0.8147 - val_loss: 0.4981 - val_accuracy: 0.7398\n",
      "Epoch 45/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.3868 - accuracy: 0.8248 - val_loss: 0.4981 - val_accuracy: 0.7317\n",
      "Epoch 46/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.3886 - accuracy: 0.8248 - val_loss: 0.4988 - val_accuracy: 0.7317\n",
      "Epoch 47/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.3854 - accuracy: 0.8208 - val_loss: 0.4996 - val_accuracy: 0.7398\n",
      "Epoch 48/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.3848 - accuracy: 0.8228 - val_loss: 0.5009 - val_accuracy: 0.7398\n",
      "Epoch 49/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.3829 - accuracy: 0.8269 - val_loss: 0.5032 - val_accuracy: 0.7398\n",
      "Epoch 50/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.3820 - accuracy: 0.8289 - val_loss: 0.5016 - val_accuracy: 0.7398\n",
      "Epoch 51/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.3821 - accuracy: 0.8289 - val_loss: 0.5040 - val_accuracy: 0.7317\n",
      "Epoch 52/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.3818 - accuracy: 0.8208 - val_loss: 0.4983 - val_accuracy: 0.7480\n",
      "Epoch 53/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.3800 - accuracy: 0.8289 - val_loss: 0.5006 - val_accuracy: 0.7317\n",
      "Epoch 54/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.3803 - accuracy: 0.8248 - val_loss: 0.5025 - val_accuracy: 0.7398\n",
      "Epoch 55/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.3787 - accuracy: 0.8310 - val_loss: 0.5019 - val_accuracy: 0.7398\n",
      "Epoch 56/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.3782 - accuracy: 0.8248 - val_loss: 0.5028 - val_accuracy: 0.7398\n",
      "Epoch 57/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.3775 - accuracy: 0.8350 - val_loss: 0.5066 - val_accuracy: 0.7480\n",
      "Epoch 58/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.3759 - accuracy: 0.8371 - val_loss: 0.5066 - val_accuracy: 0.7480\n",
      "Epoch 59/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.3752 - accuracy: 0.8391 - val_loss: 0.5092 - val_accuracy: 0.7480\n",
      "Epoch 60/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.3757 - accuracy: 0.8350 - val_loss: 0.5080 - val_accuracy: 0.7480\n",
      "Epoch 61/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.3741 - accuracy: 0.8391 - val_loss: 0.5087 - val_accuracy: 0.7480\n",
      "Epoch 62/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.3731 - accuracy: 0.8330 - val_loss: 0.5088 - val_accuracy: 0.7480\n",
      "Epoch 63/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.3727 - accuracy: 0.8391 - val_loss: 0.5105 - val_accuracy: 0.7398\n",
      "Epoch 64/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.3722 - accuracy: 0.8350 - val_loss: 0.5075 - val_accuracy: 0.7561\n",
      "Epoch 65/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.3709 - accuracy: 0.8330 - val_loss: 0.5088 - val_accuracy: 0.7398\n",
      "Epoch 66/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.3702 - accuracy: 0.8371 - val_loss: 0.5121 - val_accuracy: 0.7398\n",
      "Epoch 67/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.3692 - accuracy: 0.8350 - val_loss: 0.5098 - val_accuracy: 0.7398\n",
      "Epoch 68/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.3678 - accuracy: 0.8432 - val_loss: 0.5128 - val_accuracy: 0.7317\n",
      "Epoch 69/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.3689 - accuracy: 0.8391 - val_loss: 0.5123 - val_accuracy: 0.7317\n",
      "Epoch 70/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.3685 - accuracy: 0.8411 - val_loss: 0.5148 - val_accuracy: 0.7317\n",
      "Epoch 71/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.3687 - accuracy: 0.8432 - val_loss: 0.5170 - val_accuracy: 0.7236\n",
      "Epoch 72/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.3666 - accuracy: 0.8371 - val_loss: 0.5162 - val_accuracy: 0.7317\n",
      "Epoch 73/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.3656 - accuracy: 0.8411 - val_loss: 0.5143 - val_accuracy: 0.7317\n",
      "Epoch 74/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.3659 - accuracy: 0.8391 - val_loss: 0.5156 - val_accuracy: 0.7317\n",
      "Epoch 75/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.3649 - accuracy: 0.8391 - val_loss: 0.5181 - val_accuracy: 0.7317\n",
      "Epoch 76/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.3631 - accuracy: 0.8411 - val_loss: 0.5168 - val_accuracy: 0.7317\n",
      "Epoch 77/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.3632 - accuracy: 0.8411 - val_loss: 0.5210 - val_accuracy: 0.7317\n",
      "Epoch 78/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.3626 - accuracy: 0.8432 - val_loss: 0.5188 - val_accuracy: 0.7317\n",
      "Epoch 79/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.3608 - accuracy: 0.8452 - val_loss: 0.5214 - val_accuracy: 0.7317\n",
      "Epoch 80/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.3609 - accuracy: 0.8411 - val_loss: 0.5250 - val_accuracy: 0.7317\n",
      "Epoch 81/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.3608 - accuracy: 0.8473 - val_loss: 0.5232 - val_accuracy: 0.7317\n",
      "Epoch 82/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.3599 - accuracy: 0.8513 - val_loss: 0.5230 - val_accuracy: 0.7317\n",
      "Epoch 83/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.3589 - accuracy: 0.8473 - val_loss: 0.5216 - val_accuracy: 0.7317\n",
      "Epoch 84/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.3588 - accuracy: 0.8493 - val_loss: 0.5253 - val_accuracy: 0.7317\n",
      "Epoch 85/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.3577 - accuracy: 0.8432 - val_loss: 0.5198 - val_accuracy: 0.7398\n",
      "Epoch 86/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.3582 - accuracy: 0.8452 - val_loss: 0.5215 - val_accuracy: 0.7317\n",
      "Epoch 87/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.3565 - accuracy: 0.8473 - val_loss: 0.5252 - val_accuracy: 0.7317\n",
      "Epoch 88/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.3566 - accuracy: 0.8411 - val_loss: 0.5263 - val_accuracy: 0.7317\n",
      "Epoch 89/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.3582 - accuracy: 0.8452 - val_loss: 0.5235 - val_accuracy: 0.7317\n",
      "Epoch 90/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.3558 - accuracy: 0.8493 - val_loss: 0.5286 - val_accuracy: 0.7317\n",
      "Epoch 91/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.3552 - accuracy: 0.8452 - val_loss: 0.5260 - val_accuracy: 0.7317\n",
      "Epoch 92/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.3555 - accuracy: 0.8473 - val_loss: 0.5283 - val_accuracy: 0.7317\n",
      "Epoch 93/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.3530 - accuracy: 0.8432 - val_loss: 0.5287 - val_accuracy: 0.7317\n",
      "Epoch 94/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.3528 - accuracy: 0.8432 - val_loss: 0.5302 - val_accuracy: 0.7317\n",
      "Epoch 95/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.3527 - accuracy: 0.8452 - val_loss: 0.5280 - val_accuracy: 0.7317\n",
      "Epoch 96/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.3513 - accuracy: 0.8493 - val_loss: 0.5288 - val_accuracy: 0.7317\n",
      "Epoch 97/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.3508 - accuracy: 0.8452 - val_loss: 0.5283 - val_accuracy: 0.7317\n",
      "Epoch 98/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.3501 - accuracy: 0.8432 - val_loss: 0.5301 - val_accuracy: 0.7317\n",
      "Epoch 99/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.3504 - accuracy: 0.8411 - val_loss: 0.5312 - val_accuracy: 0.7317\n",
      "Epoch 100/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.3535 - accuracy: 0.8534 - val_loss: 0.5253 - val_accuracy: 0.7317\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6377 - accuracy: 0.7208\n",
      "테스트 손실: 0.6377, 테스트 정확도: 0.7208\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# 데이터셋 로드\n",
    "data = pd.read_csv('diabetes.csv')\n",
    "\n",
    "# 특성과 타겟 변수 분리\n",
    "X = data.drop('Outcome', axis=1).values  # 특성\n",
    "y = data['Outcome'].values               # 타겟 변수\n",
    "\n",
    "# 데이터 분할 (훈련 세트, 테스트 세트)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 데이터 정규화\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# 모델 생성\n",
    "model = keras.Sequential()\n",
    "model.add(layers.Dense(16, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "model.add(layers.Dense(8, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))  # 이진 분류를 위한 출력층\n",
    "\n",
    "# 모델 컴파일\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 모델 학습\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=10, validation_split=0.2)\n",
    "\n",
    "# 모델 평가\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'테스트 손실: {loss:.4f}, 테스트 정확도: {accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe3c968-0116-47b8-b3f6-1b337ceeee3d",
   "metadata": {},
   "source": [
    "## 3. 해당 데이터에서 Outcome을 삭제하고 BMI를 예측하는 회귀를 수행하라."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2756fe25-ce5f-467b-b40f-f66bd25f83c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "50/50 [==============================] - 1s 6ms/step - loss: 1075.3113 - mae: 31.8317 - val_loss: 1076.0687 - val_mae: 32.0346\n",
      "Epoch 2/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 1024.1301 - mae: 31.0522 - val_loss: 1015.6269 - val_mae: 31.1030\n",
      "Epoch 3/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 952.0605 - mae: 29.9307 - val_loss: 928.6648 - val_mae: 29.6964\n",
      "Epoch 4/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 847.1238 - mae: 28.2022 - val_loss: 802.1334 - val_mae: 27.4947\n",
      "Epoch 5/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 698.5999 - mae: 25.4983 - val_loss: 638.5418 - val_mae: 24.2857\n",
      "Epoch 6/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 522.6838 - mae: 21.7943 - val_loss: 463.1440 - val_mae: 20.2757\n",
      "Epoch 7/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 347.6447 - mae: 17.3158 - val_loss: 302.0273 - val_mae: 15.9186\n",
      "Epoch 8/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 213.1887 - mae: 12.9783 - val_loss: 186.6118 - val_mae: 11.9349\n",
      "Epoch 9/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 131.9353 - mae: 9.6077 - val_loss: 123.3654 - val_mae: 9.1622\n",
      "Epoch 10/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 96.3874 - mae: 7.8003 - val_loss: 94.7088 - val_mae: 7.7292\n",
      "Epoch 11/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 82.6309 - mae: 6.9953 - val_loss: 81.2487 - val_mae: 7.0482\n",
      "Epoch 12/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 76.8755 - mae: 6.5985 - val_loss: 74.6247 - val_mae: 6.7270\n",
      "Epoch 13/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 73.0351 - mae: 6.4027 - val_loss: 71.5595 - val_mae: 6.6129\n",
      "Epoch 14/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 70.1372 - mae: 6.2586 - val_loss: 68.1856 - val_mae: 6.4591\n",
      "Epoch 15/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 67.8485 - mae: 6.1315 - val_loss: 64.7973 - val_mae: 6.2597\n",
      "Epoch 16/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 65.6927 - mae: 6.0513 - val_loss: 63.2343 - val_mae: 6.2122\n",
      "Epoch 17/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 63.6350 - mae: 5.9253 - val_loss: 60.5667 - val_mae: 6.0546\n",
      "Epoch 18/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 62.0737 - mae: 5.8430 - val_loss: 59.3124 - val_mae: 5.9935\n",
      "Epoch 19/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 60.7499 - mae: 5.7849 - val_loss: 57.6066 - val_mae: 5.8943\n",
      "Epoch 20/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 59.2488 - mae: 5.6993 - val_loss: 56.3311 - val_mae: 5.8298\n",
      "Epoch 21/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 57.8679 - mae: 5.6254 - val_loss: 54.9361 - val_mae: 5.7378\n",
      "Epoch 22/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 56.6221 - mae: 5.5552 - val_loss: 53.5272 - val_mae: 5.6701\n",
      "Epoch 23/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 55.5718 - mae: 5.5007 - val_loss: 52.9611 - val_mae: 5.6457\n",
      "Epoch 24/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 54.3503 - mae: 5.4355 - val_loss: 51.6204 - val_mae: 5.5717\n",
      "Epoch 25/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 53.7298 - mae: 5.3876 - val_loss: 51.0625 - val_mae: 5.5366\n",
      "Epoch 26/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 52.3892 - mae: 5.3194 - val_loss: 50.2529 - val_mae: 5.5013\n",
      "Epoch 27/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 51.7486 - mae: 5.2606 - val_loss: 49.0335 - val_mae: 5.4320\n",
      "Epoch 28/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 50.7700 - mae: 5.2068 - val_loss: 48.4392 - val_mae: 5.4134\n",
      "Epoch 29/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 50.0713 - mae: 5.1681 - val_loss: 47.8066 - val_mae: 5.3887\n",
      "Epoch 30/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 49.0790 - mae: 5.1201 - val_loss: 47.4385 - val_mae: 5.3786\n",
      "Epoch 31/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 48.4355 - mae: 5.0758 - val_loss: 47.0743 - val_mae: 5.3547\n",
      "Epoch 32/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 48.0281 - mae: 5.0479 - val_loss: 46.5754 - val_mae: 5.3277\n",
      "Epoch 33/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 47.2408 - mae: 5.0190 - val_loss: 46.3033 - val_mae: 5.3199\n",
      "Epoch 34/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 46.6500 - mae: 4.9736 - val_loss: 45.5380 - val_mae: 5.2665\n",
      "Epoch 35/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 46.0580 - mae: 4.9391 - val_loss: 45.3294 - val_mae: 5.2734\n",
      "Epoch 36/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 45.6889 - mae: 4.9169 - val_loss: 44.6214 - val_mae: 5.2174\n",
      "Epoch 37/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 45.0695 - mae: 4.8846 - val_loss: 44.4735 - val_mae: 5.2225\n",
      "Epoch 38/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 44.5998 - mae: 4.8491 - val_loss: 43.4403 - val_mae: 5.1618\n",
      "Epoch 39/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 44.0893 - mae: 4.8163 - val_loss: 43.4437 - val_mae: 5.1553\n",
      "Epoch 40/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 43.7674 - mae: 4.8097 - val_loss: 43.3063 - val_mae: 5.1586\n",
      "Epoch 41/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 43.3205 - mae: 4.7813 - val_loss: 43.1661 - val_mae: 5.1476\n",
      "Epoch 42/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 43.0749 - mae: 4.7758 - val_loss: 43.1241 - val_mae: 5.1443\n",
      "Epoch 43/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 42.7473 - mae: 4.7532 - val_loss: 42.7524 - val_mae: 5.1186\n",
      "Epoch 44/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 42.4527 - mae: 4.7276 - val_loss: 42.7645 - val_mae: 5.1270\n",
      "Epoch 45/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 42.0743 - mae: 4.7080 - val_loss: 42.3372 - val_mae: 5.1052\n",
      "Epoch 46/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 42.1007 - mae: 4.7197 - val_loss: 42.6452 - val_mae: 5.1178\n",
      "Epoch 47/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 41.5367 - mae: 4.6878 - val_loss: 42.0802 - val_mae: 5.0804\n",
      "Epoch 48/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 41.1416 - mae: 4.6610 - val_loss: 41.9867 - val_mae: 5.0824\n",
      "Epoch 49/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 41.0470 - mae: 4.6560 - val_loss: 41.6481 - val_mae: 5.0689\n",
      "Epoch 50/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 40.8089 - mae: 4.6453 - val_loss: 41.5333 - val_mae: 5.0492\n",
      "Epoch 51/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 40.5142 - mae: 4.6202 - val_loss: 41.3023 - val_mae: 5.0346\n",
      "Epoch 52/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 40.2859 - mae: 4.6196 - val_loss: 41.3953 - val_mae: 5.0446\n",
      "Epoch 53/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 40.1145 - mae: 4.6006 - val_loss: 41.3503 - val_mae: 5.0517\n",
      "Epoch 54/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 40.1456 - mae: 4.5937 - val_loss: 41.1521 - val_mae: 5.0257\n",
      "Epoch 55/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 39.7131 - mae: 4.5861 - val_loss: 40.8723 - val_mae: 5.0091\n",
      "Epoch 56/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 39.6836 - mae: 4.5835 - val_loss: 40.1530 - val_mae: 4.9888\n",
      "Epoch 57/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 39.4116 - mae: 4.5529 - val_loss: 40.7524 - val_mae: 5.0116\n",
      "Epoch 58/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 39.2402 - mae: 4.5416 - val_loss: 40.2606 - val_mae: 4.9869\n",
      "Epoch 59/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 39.0909 - mae: 4.5442 - val_loss: 40.7644 - val_mae: 5.0117\n",
      "Epoch 60/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 38.9911 - mae: 4.5520 - val_loss: 41.1510 - val_mae: 5.0331\n",
      "Epoch 61/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 38.6825 - mae: 4.5263 - val_loss: 40.6409 - val_mae: 4.9874\n",
      "Epoch 62/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 38.7100 - mae: 4.5211 - val_loss: 40.9027 - val_mae: 5.0189\n",
      "Epoch 63/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 38.4932 - mae: 4.5142 - val_loss: 40.8596 - val_mae: 5.0208\n",
      "Epoch 64/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 38.2350 - mae: 4.5003 - val_loss: 40.6040 - val_mae: 4.9947\n",
      "Epoch 65/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 38.1340 - mae: 4.4943 - val_loss: 40.3975 - val_mae: 4.9874\n",
      "Epoch 66/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 38.0685 - mae: 4.4822 - val_loss: 40.4341 - val_mae: 4.9885\n",
      "Epoch 67/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 37.9781 - mae: 4.4907 - val_loss: 40.0998 - val_mae: 4.9643\n",
      "Epoch 68/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 37.7961 - mae: 4.4574 - val_loss: 40.1326 - val_mae: 4.9751\n",
      "Epoch 69/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 37.9880 - mae: 4.4845 - val_loss: 41.0673 - val_mae: 4.9940\n",
      "Epoch 70/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 38.0904 - mae: 4.5050 - val_loss: 40.7066 - val_mae: 4.9823\n",
      "Epoch 71/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 37.6239 - mae: 4.4746 - val_loss: 40.7793 - val_mae: 4.9955\n",
      "Epoch 72/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 37.4419 - mae: 4.4490 - val_loss: 40.4637 - val_mae: 4.9742\n",
      "Epoch 73/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 37.3878 - mae: 4.4422 - val_loss: 40.0756 - val_mae: 4.9623\n",
      "Epoch 74/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 37.2728 - mae: 4.4442 - val_loss: 40.2853 - val_mae: 4.9851\n",
      "Epoch 75/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 37.1614 - mae: 4.4342 - val_loss: 40.2135 - val_mae: 4.9871\n",
      "Epoch 76/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 37.1175 - mae: 4.4397 - val_loss: 40.0656 - val_mae: 4.9642\n",
      "Epoch 77/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 36.9796 - mae: 4.4110 - val_loss: 39.9534 - val_mae: 4.9604\n",
      "Epoch 78/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 36.9835 - mae: 4.4092 - val_loss: 39.6466 - val_mae: 4.9395\n",
      "Epoch 79/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 36.8354 - mae: 4.3993 - val_loss: 39.7136 - val_mae: 4.9392\n",
      "Epoch 80/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 36.6996 - mae: 4.3887 - val_loss: 39.5147 - val_mae: 4.9429\n",
      "Epoch 81/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 36.7813 - mae: 4.4211 - val_loss: 40.1646 - val_mae: 4.9798\n",
      "Epoch 82/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 36.7297 - mae: 4.3970 - val_loss: 39.9205 - val_mae: 4.9564\n",
      "Epoch 83/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 36.5356 - mae: 4.3775 - val_loss: 39.4227 - val_mae: 4.9279\n",
      "Epoch 84/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 36.4566 - mae: 4.3790 - val_loss: 39.3144 - val_mae: 4.9112\n",
      "Epoch 85/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 36.4163 - mae: 4.3686 - val_loss: 39.2493 - val_mae: 4.9100\n",
      "Epoch 86/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 36.3029 - mae: 4.3586 - val_loss: 39.0842 - val_mae: 4.8995\n",
      "Epoch 87/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 36.2915 - mae: 4.3658 - val_loss: 39.0329 - val_mae: 4.9075\n",
      "Epoch 88/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 36.0448 - mae: 4.3464 - val_loss: 38.7761 - val_mae: 4.8659\n",
      "Epoch 89/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 36.0484 - mae: 4.3443 - val_loss: 39.1475 - val_mae: 4.9060\n",
      "Epoch 90/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 35.9726 - mae: 4.3420 - val_loss: 38.9459 - val_mae: 4.8803\n",
      "Epoch 91/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 35.9179 - mae: 4.3414 - val_loss: 39.3406 - val_mae: 4.9106\n",
      "Epoch 92/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 35.8094 - mae: 4.3280 - val_loss: 39.4628 - val_mae: 4.9117\n",
      "Epoch 93/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 35.9383 - mae: 4.3337 - val_loss: 38.9415 - val_mae: 4.8726\n",
      "Epoch 94/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 36.0144 - mae: 4.3529 - val_loss: 39.0033 - val_mae: 4.8850\n",
      "Epoch 95/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 35.9176 - mae: 4.3379 - val_loss: 38.8086 - val_mae: 4.8902\n",
      "Epoch 96/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 35.7376 - mae: 4.3271 - val_loss: 38.6332 - val_mae: 4.8666\n",
      "Epoch 97/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 35.5347 - mae: 4.3067 - val_loss: 38.6702 - val_mae: 4.8702\n",
      "Epoch 98/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 35.6676 - mae: 4.3238 - val_loss: 38.9484 - val_mae: 4.8762\n",
      "Epoch 99/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 35.3514 - mae: 4.3011 - val_loss: 38.8878 - val_mae: 4.8668\n",
      "Epoch 100/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 35.2735 - mae: 4.3092 - val_loss: 38.7252 - val_mae: 4.8509\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 57.8076 - mae: 5.2895\n",
      "테스트 손실: 57.8076, 평균 절대 오차: 5.2895\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# CSV 파일 읽기\n",
    "df = pd.read_csv('diabetes.csv')\n",
    "\n",
    "# Outcome 열 삭제\n",
    "df = df.drop('Outcome', axis=1)\n",
    "\n",
    "# 특성과 타겟 변수 분리 (BMI를 타겟으로 설정)\n",
    "X = df.drop('BMI', axis=1).values  # 특성\n",
    "y = df['BMI'].values               # 타겟 변수 (BMI)\n",
    "\n",
    "# 데이터 분할 (훈련 세트, 테스트 세트)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 데이터 정규화\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# 모델 생성\n",
    "model = keras.Sequential()\n",
    "model.add(layers.Dense(16, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "model.add(layers.Dense(8, activation='relu'))\n",
    "model.add(layers.Dense(1))  # 회귀를 위한 출력층\n",
    "\n",
    "# 모델 컴파일\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
    "\n",
    "# 모델 학습\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=10, validation_split=0.2)\n",
    "\n",
    "# 모델 평가\n",
    "loss, mae = model.evaluate(X_test, y_test)\n",
    "print(f'테스트 손실: {loss:.4f}, 평균 절대 오차: {mae:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c84562-2d29-4b7e-9747-f99b8073da13",
   "metadata": {},
   "source": [
    "## 4. 3번과 동일하지만 dense layer만 사용한 신경만으로 회귀를 수행하라.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ef8a088-ea72-4d56-ab70-ebf693bc8478",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "50/50 [==============================] - 1s 6ms/step - loss: 1040.0756 - mae: 31.2840 - val_loss: 1019.1340 - val_mae: 31.1403\n",
      "Epoch 2/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 943.0643 - mae: 29.7568 - val_loss: 891.9924 - val_mae: 29.0479\n",
      "Epoch 3/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 783.7164 - mae: 27.0211 - val_loss: 692.4353 - val_mae: 25.3716\n",
      "Epoch 4/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 557.8641 - mae: 22.5264 - val_loss: 441.9905 - val_mae: 19.7602\n",
      "Epoch 5/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 315.7254 - mae: 16.2261 - val_loss: 218.9198 - val_mae: 12.9334\n",
      "Epoch 6/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 148.2256 - mae: 10.2821 - val_loss: 104.3747 - val_mae: 8.2836\n",
      "Epoch 7/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 89.5787 - mae: 7.2216 - val_loss: 78.0490 - val_mae: 6.9590\n",
      "Epoch 8/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 78.3858 - mae: 6.5736 - val_loss: 72.1946 - val_mae: 6.6477\n",
      "Epoch 9/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 73.7256 - mae: 6.3461 - val_loss: 69.1806 - val_mae: 6.4665\n",
      "Epoch 10/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 70.3341 - mae: 6.2028 - val_loss: 66.7999 - val_mae: 6.3310\n",
      "Epoch 11/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 67.2526 - mae: 6.0453 - val_loss: 63.9467 - val_mae: 6.1472\n",
      "Epoch 12/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 64.7193 - mae: 5.9264 - val_loss: 62.3025 - val_mae: 6.0773\n",
      "Epoch 13/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 62.3645 - mae: 5.8163 - val_loss: 60.3024 - val_mae: 5.9549\n",
      "Epoch 14/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 60.2562 - mae: 5.7085 - val_loss: 58.2300 - val_mae: 5.8410\n",
      "Epoch 15/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 58.4362 - mae: 5.6266 - val_loss: 56.8338 - val_mae: 5.7656\n",
      "Epoch 16/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 56.7129 - mae: 5.5223 - val_loss: 55.9375 - val_mae: 5.7222\n",
      "Epoch 17/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 55.2438 - mae: 5.4422 - val_loss: 54.5308 - val_mae: 5.6616\n",
      "Epoch 18/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 54.0756 - mae: 5.3720 - val_loss: 53.0300 - val_mae: 5.5764\n",
      "Epoch 19/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 52.7284 - mae: 5.3004 - val_loss: 52.3253 - val_mae: 5.5559\n",
      "Epoch 20/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 51.5515 - mae: 5.2415 - val_loss: 51.2609 - val_mae: 5.5127\n",
      "Epoch 21/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 50.2841 - mae: 5.1594 - val_loss: 50.5320 - val_mae: 5.4623\n",
      "Epoch 22/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 49.5356 - mae: 5.0953 - val_loss: 49.7719 - val_mae: 5.4527\n",
      "Epoch 23/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 48.4793 - mae: 5.0486 - val_loss: 49.1121 - val_mae: 5.4109\n",
      "Epoch 24/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 47.6274 - mae: 5.0052 - val_loss: 48.3439 - val_mae: 5.3845\n",
      "Epoch 25/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 46.8608 - mae: 4.9501 - val_loss: 47.5072 - val_mae: 5.3494\n",
      "Epoch 26/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 46.1517 - mae: 4.9086 - val_loss: 46.8578 - val_mae: 5.3355\n",
      "Epoch 27/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 45.5188 - mae: 4.8737 - val_loss: 47.0169 - val_mae: 5.3183\n",
      "Epoch 28/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 44.9848 - mae: 4.8394 - val_loss: 46.4373 - val_mae: 5.3131\n",
      "Epoch 29/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 44.7001 - mae: 4.8253 - val_loss: 46.0899 - val_mae: 5.2934\n",
      "Epoch 30/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 43.6309 - mae: 4.7517 - val_loss: 45.0956 - val_mae: 5.2618\n",
      "Epoch 31/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 42.9734 - mae: 4.7128 - val_loss: 44.9116 - val_mae: 5.2608\n",
      "Epoch 32/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 42.7826 - mae: 4.6884 - val_loss: 44.2115 - val_mae: 5.2424\n",
      "Epoch 33/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 42.1019 - mae: 4.6712 - val_loss: 44.6287 - val_mae: 5.2512\n",
      "Epoch 34/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 41.7875 - mae: 4.6357 - val_loss: 43.9269 - val_mae: 5.2168\n",
      "Epoch 35/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 41.2880 - mae: 4.6075 - val_loss: 43.7557 - val_mae: 5.2368\n",
      "Epoch 36/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 40.9427 - mae: 4.5928 - val_loss: 43.3330 - val_mae: 5.2045\n",
      "Epoch 37/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 40.6149 - mae: 4.5759 - val_loss: 42.9248 - val_mae: 5.1739\n",
      "Epoch 38/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 40.3062 - mae: 4.5590 - val_loss: 43.1384 - val_mae: 5.1968\n",
      "Epoch 39/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 40.0612 - mae: 4.5417 - val_loss: 43.2880 - val_mae: 5.1636\n",
      "Epoch 40/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 39.5418 - mae: 4.5089 - val_loss: 43.1403 - val_mae: 5.1986\n",
      "Epoch 41/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 39.3823 - mae: 4.5101 - val_loss: 42.6608 - val_mae: 5.1591\n",
      "Epoch 42/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 38.8865 - mae: 4.4842 - val_loss: 42.3556 - val_mae: 5.1338\n",
      "Epoch 43/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 38.7699 - mae: 4.4491 - val_loss: 41.6843 - val_mae: 5.1347\n",
      "Epoch 44/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 38.4783 - mae: 4.4416 - val_loss: 41.4001 - val_mae: 5.0991\n",
      "Epoch 45/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 38.1547 - mae: 4.4255 - val_loss: 42.0929 - val_mae: 5.1139\n",
      "Epoch 46/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 38.0742 - mae: 4.4455 - val_loss: 41.3590 - val_mae: 5.1194\n",
      "Epoch 47/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 37.7123 - mae: 4.4114 - val_loss: 41.0469 - val_mae: 5.0868\n",
      "Epoch 48/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 37.5133 - mae: 4.3851 - val_loss: 41.4274 - val_mae: 5.0862\n",
      "Epoch 49/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 37.1289 - mae: 4.3788 - val_loss: 40.7506 - val_mae: 5.0458\n",
      "Epoch 50/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 37.0262 - mae: 4.3794 - val_loss: 41.0843 - val_mae: 5.0572\n",
      "Epoch 51/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 36.9027 - mae: 4.3579 - val_loss: 40.3203 - val_mae: 5.0349\n",
      "Epoch 52/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 36.7215 - mae: 4.3555 - val_loss: 40.3849 - val_mae: 5.0309\n",
      "Epoch 53/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 36.5316 - mae: 4.3392 - val_loss: 40.3963 - val_mae: 5.0493\n",
      "Epoch 54/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 36.3266 - mae: 4.3393 - val_loss: 40.3024 - val_mae: 5.0384\n",
      "Epoch 55/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 36.3449 - mae: 4.3393 - val_loss: 40.1236 - val_mae: 5.0093\n",
      "Epoch 56/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 36.0930 - mae: 4.3021 - val_loss: 39.9864 - val_mae: 4.9908\n",
      "Epoch 57/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 36.2754 - mae: 4.3265 - val_loss: 41.1940 - val_mae: 5.0223\n",
      "Epoch 58/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 35.8884 - mae: 4.3158 - val_loss: 40.7156 - val_mae: 5.0131\n",
      "Epoch 59/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 35.6593 - mae: 4.3018 - val_loss: 40.3683 - val_mae: 5.0302\n",
      "Epoch 60/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 35.4400 - mae: 4.2853 - val_loss: 40.1665 - val_mae: 4.9668\n",
      "Epoch 61/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 35.3551 - mae: 4.2682 - val_loss: 39.7988 - val_mae: 4.9522\n",
      "Epoch 62/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 35.1452 - mae: 4.2652 - val_loss: 39.7781 - val_mae: 4.9650\n",
      "Epoch 63/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 35.0673 - mae: 4.2796 - val_loss: 39.6426 - val_mae: 4.9586\n",
      "Epoch 64/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 35.2566 - mae: 4.2982 - val_loss: 39.8656 - val_mae: 4.9626\n",
      "Epoch 65/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 35.0045 - mae: 4.2591 - val_loss: 39.7743 - val_mae: 4.9608\n",
      "Epoch 66/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 34.7962 - mae: 4.2468 - val_loss: 39.3603 - val_mae: 4.9316\n",
      "Epoch 67/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 34.7263 - mae: 4.2552 - val_loss: 39.5839 - val_mae: 4.9392\n",
      "Epoch 68/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 34.4371 - mae: 4.2417 - val_loss: 39.4999 - val_mae: 4.9334\n",
      "Epoch 69/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 34.3688 - mae: 4.2185 - val_loss: 40.0209 - val_mae: 4.9557\n",
      "Epoch 70/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 34.3232 - mae: 4.2271 - val_loss: 40.1392 - val_mae: 4.9567\n",
      "Epoch 71/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 34.1144 - mae: 4.2236 - val_loss: 39.9367 - val_mae: 4.9555\n",
      "Epoch 72/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 34.1472 - mae: 4.2077 - val_loss: 40.0045 - val_mae: 4.9334\n",
      "Epoch 73/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 34.0361 - mae: 4.2117 - val_loss: 39.4208 - val_mae: 4.9285\n",
      "Epoch 74/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 33.6817 - mae: 4.1846 - val_loss: 39.7274 - val_mae: 4.9379\n",
      "Epoch 75/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 33.9223 - mae: 4.2233 - val_loss: 39.3665 - val_mae: 4.9111\n",
      "Epoch 76/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 33.6252 - mae: 4.1823 - val_loss: 39.0905 - val_mae: 4.8934\n",
      "Epoch 77/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 33.5780 - mae: 4.2047 - val_loss: 39.3527 - val_mae: 4.9101\n",
      "Epoch 78/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 33.9001 - mae: 4.2107 - val_loss: 39.3573 - val_mae: 4.9241\n",
      "Epoch 79/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 33.4928 - mae: 4.1998 - val_loss: 39.0148 - val_mae: 4.8969\n",
      "Epoch 80/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 33.3585 - mae: 4.1567 - val_loss: 39.7610 - val_mae: 4.9448\n",
      "Epoch 81/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 32.9339 - mae: 4.1687 - val_loss: 39.4320 - val_mae: 4.9196\n",
      "Epoch 82/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 33.0262 - mae: 4.1443 - val_loss: 39.3301 - val_mae: 4.9057\n",
      "Epoch 83/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 33.0490 - mae: 4.1626 - val_loss: 39.5235 - val_mae: 4.9456\n",
      "Epoch 84/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 32.9737 - mae: 4.1554 - val_loss: 39.3716 - val_mae: 4.9085\n",
      "Epoch 85/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 32.8927 - mae: 4.1642 - val_loss: 39.5677 - val_mae: 4.9128\n",
      "Epoch 86/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 32.6287 - mae: 4.1361 - val_loss: 39.1527 - val_mae: 4.8696\n",
      "Epoch 87/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 32.6237 - mae: 4.1412 - val_loss: 39.2498 - val_mae: 4.8954\n",
      "Epoch 88/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 32.5390 - mae: 4.1443 - val_loss: 39.3701 - val_mae: 4.9060\n",
      "Epoch 89/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 32.4507 - mae: 4.1136 - val_loss: 38.1879 - val_mae: 4.8370\n",
      "Epoch 90/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 32.3135 - mae: 4.1063 - val_loss: 38.7982 - val_mae: 4.8657\n",
      "Epoch 91/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 32.4574 - mae: 4.1466 - val_loss: 39.7697 - val_mae: 4.9002\n",
      "Epoch 92/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 32.7797 - mae: 4.1944 - val_loss: 40.0524 - val_mae: 4.9336\n",
      "Epoch 93/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 31.9571 - mae: 4.1048 - val_loss: 39.2506 - val_mae: 4.8720\n",
      "Epoch 94/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 32.0084 - mae: 4.0862 - val_loss: 39.4036 - val_mae: 4.8783\n",
      "Epoch 95/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 32.1167 - mae: 4.1192 - val_loss: 39.1610 - val_mae: 4.8829\n",
      "Epoch 96/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 31.8729 - mae: 4.0877 - val_loss: 38.9823 - val_mae: 4.8646\n",
      "Epoch 97/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 31.9350 - mae: 4.1164 - val_loss: 39.5592 - val_mae: 4.9047\n",
      "Epoch 98/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 31.9879 - mae: 4.0737 - val_loss: 37.8936 - val_mae: 4.8274\n",
      "Epoch 99/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 31.6729 - mae: 4.0567 - val_loss: 38.6861 - val_mae: 4.8520\n",
      "Epoch 100/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 31.9733 - mae: 4.1168 - val_loss: 38.8564 - val_mae: 4.8949\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 62.6326 - mae: 5.4545\n",
      "테스트 손실: 62.6326, 평균 절대 오차: 5.4545\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# CSV 파일 읽기\n",
    "df = pd.read_csv('diabetes.csv')\n",
    "\n",
    "# Outcome 열 삭제\n",
    "df = df.drop('Outcome', axis=1)\n",
    "\n",
    "# 특성과 타겟 변수 분리 (BMI를 타겟으로 설정)\n",
    "X = df.drop('BMI', axis=1).values  # 특성\n",
    "y = df['BMI'].values               # 타겟 변수 (BMI)\n",
    "\n",
    "# 데이터 분할 (훈련 세트, 테스트 세트)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 데이터 정규화\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# 모델 생성\n",
    "model = keras.Sequential()\n",
    "model.add(layers.Dense(32, activation='relu', input_shape=(X_train.shape[1],)))    # 첫 번째 Dense 레이어\n",
    "model.add(layers.Dense(16, activation='relu'))                                     # 두 번째 Dense 레이어\n",
    "model.add(layers.Dense(1))                                                         # 회귀를 위한 출력층\n",
    "\n",
    "# 모델 컴파일\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
    "\n",
    "# 모델 학습\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=10, validation_split=0.2)\n",
    "\n",
    "# 모델 평가\n",
    "loss, mae = model.evaluate(X_test, y_test)\n",
    "print(f'테스트 손실: {loss:.4f}, 평균 절대 오차: {mae:.4f}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
